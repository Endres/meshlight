MeshConnector:
  - does all the network stuff
  - simple by design, nothing too special, any intelligence must be in higher layers
  - only intelligence is to save low level traffic, so to say: (but even this could go to the next layer)
    - if no node is connected, don't send at all (where to?)
    - if less than one bit of data is to be transmitted, do not send (maybe could be overridden for 0-bit "pokes")
  - handles the number of connected nodes (important parameter for animations) and informs somehow the next layer about changes (or will simply be polled)
  - offers one main function "broadcast(data)" where data consists of the raw network data to be broadcasted in the mesh
  - ideally this would be the painlessMesh Library, but I doubt a python implementation does exist, so let's write our own wrapper

TimeFrameRunner:
  - is effectively an extra thread
  - calls animation classes depending on currently set animation
  - calculates FPS utilization
  - given: TARGET_FPS (e.g. 10,15,20,60 FPS)
  - if execution of animation (+ tasks afterwards, such as broadcasting via Wi-Fi or updating thread output variables like RGB data and current FPS)
    is slower than 1/TARGET_FPS:
    - run next animation step, but with additional argument "skip=True".
    - slower animations can then make use of this and only increment counters or the like, but not actually generate new output
    - output furthermore will not be sent / updated /... to save time now
    - if enough frames skipped to be again on track, switch to normal mode again
  - normal mode / execution time faster than 1/TARGET_FPS:
    - run animation, broadcasting, data updates,...
    - rest of time until 1/TARGET_FPS is then sleep.
  - interesting: this layer can decide when to broadcast updates (or even intelligently unicast single changes), because it always is in the middle between network and content generation (animations), thus also acts as some kind of frame buffer, yeah! IoT frame buffer! :D

AnimationCollection:
  - lists all available animations, this is particularly useful for the web interface to be able to select from available animations
  - in the first version this was also handling the sequencing part (next section), however this should most probably be split up
  - as the feature set of AnimationCollection is little, this might be just implemented as module methods, or later on can be a whole class (saves resources)

AnimationSequence:
  - some kind of "auto play" feature
    - maybe automatically enabled after a specific amount of no user interaction...? (should be also be able to be disabled)
  - has a list of animations with their respective options that is played back. Options might be set through the web interface.
  - We definitely need some kind of mode switching between single animation mode and sequence playback in the web interface
  - eventhough, while playing animations, we can edit parameters of each sequence step
  - in single mode we are also able to edit the parameters, and probably to add current set to the sequence

Events:
  - there is some kind of event handling, maybe in yet another thread to make it more comfortable
  - the event queue circles through every current queue element
  - queue elements are executed once per event class loop (in other words, events with the same event information trigger at the exact same time, so they will be added to the current event queue)
    - the event class "GeoTimed" typically loops once a day (trigger is the specific time like Sunrise or Sunset)
    - the event class "Always" loops all over whenever

Animations:
  - get called via TimeFrameRunner, which itself gets information about animation to run by the flask server
  - offer one important function named "frame(data, skip)". data consists of the rather universal I/O content that is processed here
  - the frame function can process the previous data and usually returns the next data (great for Animations!)
  - usually, because if skip=True, nothing needs to be returned (but for very simple animations, can but will be disposed anyway)
  - furthermore there must be some kind of a FPS base (maybe helpers?) so it can handle its process based on the target FPS rate.
    - think of a circular chaser animation that moves around the whole circle once every second
    - in this case we have 15 spots around the circle, so every forth frame the next spot has to get lit, to achieve the target of 60 FPS
    - simplest would be to include a frame counter and calculate based on that counter.
    ! (compare this planning note with the actual implementation of our very first animation, the RGBFader) !
  - the init function takes a configuration set (that contains all non-default parameters; what is even default??)
  - this configuration set is compared against a default configuration set and only changed parametes will be overridden
  - also, we need to be able to retreive the current configuration set including ranges and parameter types, from this information the web interface options will be generated
  - and the parameters might be changed on-the-fly
